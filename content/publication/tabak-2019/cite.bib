@article{tabak2019,
 abstract = {Motion-activated cameras (“camera traps”) are increasingly used in ecological and management studies for remotely observing wildlife and are amongst the most powerful tools for wildlife research. However, studies involving camera traps result in millions of images that need to be analysed, typically by visually observing each image, in order to extract data that can be used in ecological analyses. We trained machine learning models using convolutional neural networks with the ResNet-18 architecture and 3,367,383 images to automatically classify wildlife species from camera trap images obtained from five states across the United States. We tested our model on an independent subset of images not seen during training from the United States and on an out-of-sample (or “out-of-distribution” in the machine learning literature) dataset of ungulate images from Canada. We also tested the ability of our model to distinguish empty images from those with animals in another out-of-sample dataset from Tanzania, containing a faunal community that was novel to the model. The trained model classified approximately 2,000 images per minute on a laptop computer with 16 gigabytes of RAM. The trained model achieved 98% accuracy at identifying species in the United States, the highest accuracy of such a model to date. Out-of-sample validation from Canada achieved 82% accuracy and correctly identified 94% of images containing an animal in the dataset from Tanzania. We provide an r package (Machine Learning for Wildlife Image Classification) that allows the users to (a) use the trained model presented here and (b) train their own model using classified images of wildlife from their studies. The use of machine learning to rapidly and accurately classify wildlife in camera trap images can facilitate non-invasive sampling designs in ecological studies by reducing the burden of manually analysing images. Our r package makes these methods accessible to ecologists.},
 author = {Tabak, Michael A. and Norouzzadeh, Mohammad S. and Wolfson, David W. and Sweeney, Steven J. and Vercauteren, Kurt C. and Snow, Nathan P. and Halseth, Joseph M. and Salvo, Paul A. Di and Lewis, Jesse S. and White, Michael D. and Teton, Ben and Beasley, James C. and Schlichting, Peter E. and Boughton, Raoul K. and Wight, Bethany and Newkirk, Eric S. and Ivan, Jacob S. and Odell, Eric A. and Brook, Ryan K. and Lukacs, Paul M. and Moeller, Anna K. and Mandeville, Elizabeth G. and Clune, Jeff and Miller, Ryan S.},
 copyright = {© 2018 The Authors. Methods in Ecology and Evolution © 2018 British Ecological Society},
 doi = {10.1111/2041-210X.13120},
 file = {Full Text PDF:C\:\\Users\\David\\Zotero\\storage\\N3FJ49TT\\Tabak et al. - 2019 - Machine learning to classify animal species in cam.pdf:application/pdf;Snapshot:C\:\\Users\\David\\Zotero\\storage\\VWTGW7MZ\\2041-210X.html:text/html},
 issn = {2041-210X},
 journal = {Methods in Ecology and Evolution},
 keywords = {artificial intelligence, camera trap, convolutional neural network, deep neural networks, image classification, machine learning, r package, remote sensing},
 language = {en},
 note = {_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13120},
 number = {4},
 pages = {585--590},
 shorttitle = {Machine learning to classify animal species in camera trap images},
 title = {Machine learning to classify animal species in camera trap images: Applications in ecology},
 url = {http://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13120},
 urldate = {2020-09-07},
 volume = {10},
 year = {2019}
}

